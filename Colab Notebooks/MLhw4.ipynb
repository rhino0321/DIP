{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOqnUoC7rtni/S4tsXjtALX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bxl30f3defQc","executionInfo":{"status":"ok","timestamp":1686724250022,"user_tz":-480,"elapsed":360,"user":{"displayName":"許嘉允","userId":"12091613254688714630"}},"outputId":"d8b434a2-efd3-4a02-a592-7c10a5137ef6"},"outputs":[{"output_type":"stream","name":"stdout","text":["z prediction: 0.9795583826286123\n"]}],"source":["import numpy as np\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","def logistic_regression(x, y):\n","    theta = np.random.randn(x.shape[0])\n","    learning_rate = 0.1\n","    num_iterations = 1000\n","    for _ in range(num_iterations):\n","        h = sigmoid(np.dot(x, theta))\n","        error = h - y\n","        gradient = np.dot(x.T, error) / len(x)\n","        theta -= learning_rate * gradient\n","    return theta\n","x = np.array([0, 1])\n","y = np.array([0, 1])\n","z = np.array([0, 1])\n","theta = logistic_regression(x, y)\n","prediction = sigmoid(np.dot(z, theta))\n","print(\"z prediction:\", prediction)"]}]}